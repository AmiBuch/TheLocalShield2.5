<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Transcription with Whisper</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: white;
        }
        
        .container {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.37);
            border: 1px solid rgba(255, 255, 255, 0.18);
        }
        
        h1 {
            text-align: center;
            margin-bottom: 30px;
            font-size: 2.5em;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        
        .recording-section {
            text-align: center;
            margin-bottom: 30px;
        }
        
        .record-button {
            background: linear-gradient(45deg, #ff6b6b, #ee5a24);
            border: none;
            border-radius: 50%;
            width: 120px;
            height: 120px;
            font-size: 24px;
            color: white;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(0,0,0,0.2);
            margin: 20px;
        }
        
        .record-button:hover {
            transform: scale(1.05);
            box-shadow: 0 6px 20px rgba(0,0,0,0.3);
        }
        
        .record-button.recording {
            background: linear-gradient(45deg, #ff4757, #c44569);
            animation: pulse 1s infinite;
        }
        
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }
        
        .timer {
            font-size: 2em;
            font-weight: bold;
            margin: 20px 0;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        
        .status {
            font-size: 1.2em;
            margin: 15px 0;
            padding: 10px;
            border-radius: 10px;
            background: rgba(255, 255, 255, 0.1);
        }
        
        .transcription-section {
            margin-top: 30px;
        }
        
        .transcription-box {
            background: rgba(255, 255, 255, 0.9);
            color: #333;
            border-radius: 15px;
            padding: 20px;
            min-height: 150px;
            font-size: 1.1em;
            line-height: 1.6;
            box-shadow: inset 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .audio-controls {
            margin: 20px 0;
            text-align: center;
        }
        
        audio {
            width: 100%;
            max-width: 400px;
            margin: 10px 0;
        }
        
        .loading {
            display: none;
            text-align: center;
            margin: 20px 0;
        }
        
        .spinner {
            border: 4px solid rgba(255, 255, 255, 0.3);
            border-radius: 50%;
            border-top: 4px solid white;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
            margin: 0 auto;
        }
        
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ Voice Transcription</h1>
        
        <div class="recording-section">
            <button id="recordButton" class="record-button">
                üéôÔ∏è Start Recording
            </button>
            <div id="timer" class="timer">00:00</div>
            <div id="status" class="status">Ready to record</div>
        </div>
        
        <div class="audio-controls">
            <audio id="audioPlayback" controls style="display: none;"></audio>
        </div>
        
        <div class="loading" id="loading">
            <div class="spinner"></div>
            <p>Transcribing audio...</p>
        </div>
        
        <div class="transcription-section">
            <h2>üìù Transcription</h2>
            <div id="transcriptionBox" class="transcription-box">
                Your transcribed text will appear here...
            </div>
        </div>
    </div>

    <script>
        class VoiceTranscriber {
            constructor() {
                this.mediaRecorder = null;
                this.audioChunks = [];
                this.isRecording = false;
                this.recordingTime = 0;
                this.maxRecordingTime = 30; // 30 seconds
                this.timer = null;
                
                this.recordButton = document.getElementById('recordButton');
                this.timerDisplay = document.getElementById('timer');
                this.statusDisplay = document.getElementById('status');
                this.audioPlayback = document.getElementById('audioPlayback');
                this.transcriptionBox = document.getElementById('transcriptionBox');
                this.loading = document.getElementById('loading');
                
                this.initializeEventListeners();
                this.checkMicrophonePermissions();
            }
            
            initializeEventListeners() {
                this.recordButton.addEventListener('click', () => {
                    if (this.isRecording) {
                        this.stopRecording();
                    } else {
                        this.startRecording();
                    }
                });
            }
            
            async checkMicrophonePermissions() {
                try {
                    // Check if getUserMedia is supported
                    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                        this.statusDisplay.textContent = 'Microphone not supported by this browser. Please use Chrome, Firefox, or Safari.';
                        this.statusDisplay.style.color = '#ff6b6b';
                        this.recordButton.disabled = true;
                        return;
                    }
                    
                    // Check microphone permissions
                    const permissionStatus = await navigator.permissions.query({ name: 'microphone' });
                    
                    if (permissionStatus.state === 'denied') {
                        this.statusDisplay.textContent = 'Microphone access denied. Please enable microphone permissions in browser settings.';
                        this.statusDisplay.style.color = '#ff6b6b';
                    } else if (permissionStatus.state === 'granted') {
                        this.statusDisplay.textContent = 'Ready to record - microphone access granted';
                        this.statusDisplay.style.color = '#4ade80';
                    } else {
                        this.statusDisplay.textContent = 'Click record to allow microphone access';
                        this.statusDisplay.style.color = '#fbbf24';
                    }
                } catch (error) {
                    console.log('Permission check not supported, will check on first record attempt');
                    this.statusDisplay.textContent = 'Ready to record';
                }
            }
            
            async startRecording() {
                try {
                    console.log('Requesting microphone access...');
                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            echoCancellation: true,
                            noiseSuppression: true,
                            sampleRate: 44100
                        } 
                    });
                    
                    console.log('Microphone access granted');
                    console.log('Audio tracks:', stream.getAudioTracks().length);
                    
                    // Try different audio formats for better compatibility
                    let options = [
                        { mimeType: 'audio/webm;codecs=opus' },
                        { mimeType: 'audio/webm' },
                        { mimeType: 'audio/mp4' },
                        { mimeType: 'audio/ogg;codecs=opus' },
                        { mimeType: 'audio/wav' }
                    ];
                    
                    let selectedOptions = {};
                    for (let option of options) {
                        if (option.mimeType && MediaRecorder.isTypeSupported(option.mimeType)) {
                            selectedOptions = option;
                            console.log('‚úì Using audio format:', option.mimeType);
                            break;
                        }
                    }
                    
                    // Fallback to no specific format
                    if (!selectedOptions.mimeType) {
                        console.log('‚ö† Using default audio format');
                    }
                    
                    this.mediaRecorder = new MediaRecorder(stream, selectedOptions);
                    this.selectedMimeType = selectedOptions.mimeType || 'audio/webm';
                    
                    this.audioChunks = [];
                    this.recordingTime = 0;
                    
                    console.log('MediaRecorder state:', this.mediaRecorder.state);
                    console.log('MediaRecorder mimeType:', this.mediaRecorder.mimeType);
                    
                    this.mediaRecorder.ondataavailable = (event) => {
                        console.log('ondataavailable fired - size:', event.data.size, 'bytes');
                        if (event.data.size > 0) {
                            this.audioChunks.push(event.data);
                            console.log('‚úì Audio chunk added. Total chunks:', this.audioChunks.length);
                        } else {
                            console.warn('‚ö† Empty audio chunk received');
                        }
                    };
                    
                    this.mediaRecorder.onstart = () => {
                        console.log('‚úì MediaRecorder started');
                    };
                    
                    this.mediaRecorder.onstop = () => {
                        console.log('‚úì MediaRecorder stopped. Total chunks:', this.audioChunks.length);
                        this.processRecording();
                    };
                    
                    this.mediaRecorder.onerror = (event) => {
                        console.error('‚ùå MediaRecorder error:', event.error);
                    };
                    
                    // Start recording - request data every 1000ms (1 second)
                    console.log('Starting MediaRecorder with 1000ms timeslice...');
                    this.mediaRecorder.start(1000);
                    this.isRecording = true;
                    
                    this.updateUI();
                    this.startTimer();
                    
                    // Auto-stop after 30 seconds
                    setTimeout(() => {
                        if (this.isRecording) {
                            console.log('Auto-stopping recording (30 second limit)');
                            this.stopRecording();
                        }
                    }, this.maxRecordingTime * 1000);
                    
                } catch (error) {
                    console.error('Error starting recording:', error);
                    let errorMessage = 'Error: Could not access microphone';
                    
                    if (error.name === 'NotAllowedError') {
                        errorMessage = 'Microphone access denied. Please allow microphone permissions in your browser.';
                    } else if (error.name === 'NotFoundError') {
                        errorMessage = 'No microphone found. Please connect a microphone and try again.';
                    } else if (error.name === 'NotSupportedError') {
                        errorMessage = 'Microphone not supported by this browser. Try Chrome or Firefox.';
                    } else if (error.name === 'NotReadableError') {
                        errorMessage = 'Microphone is being used by another application. Please close other apps using the microphone.';
                    }
                    
                    this.statusDisplay.textContent = errorMessage;
                    this.statusDisplay.style.color = '#ff6b6b';
                }
            }
            
            stopRecording() {
                if (this.mediaRecorder && this.isRecording) {
                    console.log('Stopping recording. Time recorded:', this.recordingTime, 'seconds');
                    console.log('Chunks collected so far:', this.audioChunks.length);
                    
                    this.mediaRecorder.stop();
                    this.mediaRecorder.stream.getTracks().forEach(track => track.stop());
                    this.isRecording = false;
                    this.clearTimer();
                    this.updateUI();
                }
            }
            
            startTimer() {
                this.timer = setInterval(() => {
                    this.recordingTime++;
                    this.updateTimerDisplay();
                    
                    if (this.recordingTime >= this.maxRecordingTime) {
                        this.stopRecording();
                    }
                }, 1000);
            }
            
            clearTimer() {
                if (this.timer) {
                    clearInterval(this.timer);
                    this.timer = null;
                }
            }
            
            updateTimerDisplay() {
                const minutes = Math.floor(this.recordingTime / 60);
                const seconds = this.recordingTime % 60;
                this.timerDisplay.textContent = 
                    `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}`;
            }
            
            updateUI() {
                if (this.isRecording) {
                    this.recordButton.textContent = '‚èπÔ∏è Stop Recording';
                    this.recordButton.classList.add('recording');
                    this.statusDisplay.textContent = 'Recording... Speak now!';
                    this.statusDisplay.style.color = '#4ade80';
                } else {
                    this.recordButton.textContent = 'üéôÔ∏è Start Recording';
                    this.recordButton.classList.remove('recording');
                    this.statusDisplay.textContent = 'Ready to record';
                    this.statusDisplay.style.color = 'white';
                }
            }
            
            async processRecording() {
                console.log('=== Processing Recording ===');
                console.log('Total chunks collected:', this.audioChunks.length);
                
                if (this.audioChunks.length === 0) {
                    console.error('‚ùå No audio chunks collected!');
                    this.statusDisplay.textContent = 'No audio recorded - try a different browser or check microphone settings';
                    this.statusDisplay.style.color = '#ff6b6b';
                    return;
                }
                
                // Log each chunk size
                this.audioChunks.forEach((chunk, i) => {
                    console.log(`Chunk ${i}: ${chunk.size} bytes, type: ${chunk.type}`);
                });
                
                const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
                console.log('Total audio blob size:', audioBlob.size, 'bytes');
                console.log('Audio blob type:', audioBlob.type);
                
                // Check if blob is large enough (at least 1KB for a valid recording)
                if (audioBlob.size < 1000) {
                    console.warn('‚ö† Audio blob too small:', audioBlob.size, 'bytes');
                    this.statusDisplay.textContent = `Recording too short (${audioBlob.size} bytes). Please speak louder and record for at least 2 seconds.`;
                    this.statusDisplay.style.color = '#ff6b6b';
                    
                    // Still show the audio player for debugging
                    const audioUrl = URL.createObjectURL(audioBlob);
                    this.audioPlayback.src = audioUrl;
                    this.audioPlayback.style.display = 'block';
                    return;
                }
                
                const audioUrl = URL.createObjectURL(audioBlob);
                
                // Show audio player
                this.audioPlayback.src = audioUrl;
                this.audioPlayback.style.display = 'block';
                console.log('‚úì Audio player ready');
                
                // Convert to format suitable for Whisper
                await this.transcribeAudio(audioBlob);
            }
            
            // Helper function to properly convert Blob to base64
            blobToBase64(blob) {
                return new Promise((resolve, reject) => {
                    const reader = new FileReader();
                    reader.onloadend = () => {
                        // Remove the data URL prefix (e.g., "data:audio/webm;base64,")
                        const base64 = reader.result.split(',')[1];
                        resolve(base64);
                    };
                    reader.onerror = reject;
                    reader.readAsDataURL(blob);
                });
            }
            
            async transcribeAudio(audioBlob) {
                this.loading.style.display = 'block';
                this.statusDisplay.textContent = 'Transcribing audio...';
                
                try {
                    // Convert blob to base64 for sending to backend
                    const base64Audio = await this.blobToBase64(audioBlob);
                    
                    console.log('Audio blob size:', audioBlob.size, 'bytes');
                    console.log('Base64 length:', base64Audio.length);
                    
                    // Send to Whisper backend for transcription
                    const response = await fetch('/transcribe', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({
                            audio: base64Audio,
                            format: 'webm'
                        })
                    });
                    
                    if (!response.ok) {
                        const errorData = await response.json();
                        throw new Error(errorData.error || `Server error: ${response.status}`);
                    }
                    
                    const result = await response.json();
                    
                    if (result.success) {
                        this.displayTranscription(result.text);
                        if (result.language) {
                            this.statusDisplay.textContent = `Transcription completed! (Language: ${result.language})`;
                        }
                    } else {
                        throw new Error(result.error || 'Transcription failed');
                    }
                    
                } catch (error) {
                    console.error('Transcription error:', error);
                    this.statusDisplay.textContent = 'Error during transcription';
                    this.statusDisplay.style.color = '#ff6b6b';
                    this.transcriptionBox.textContent = `Transcription failed: ${error.message}. Make sure the server is running.`;
                } finally {
                    this.loading.style.display = 'none';
                }
            }
            
            
            displayTranscription(text) {
                this.transcriptionBox.textContent = text;
                this.statusDisplay.textContent = 'Transcription completed!';
                this.statusDisplay.style.color = '#4ade80';
            }
        }
        
        // Initialize the voice transcriber when the page loads
        document.addEventListener('DOMContentLoaded', () => {
            new VoiceTranscriber();
        });
    </script>
</body>
</html>

